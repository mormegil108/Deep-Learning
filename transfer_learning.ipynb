{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gudaKYgghN2n"
   },
   "source": [
    "# Transfer Learning\n",
    "\n",
    "- In this notebook, we will work with the CIFAR-10 dataset.\n",
    "- This is a well-known dataset for image classification, which includes 60000 32x32 color images in 10 classes, with 6000 images per class.\n",
    "- There are 50000 training images and 10000 test images.\n",
    "- The ten classes are: [airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck].\n",
    "- To illustrate the power and concept of transfer learning, we will first train a CNN model on the following classes only (airplane, automobile, bird, cat, deer).\n",
    "- Then we will train only the last layer(s) of the network on the classes (dog, frog, horse, ship, truck) and see how well the features learned on (airplane, automobile, bird, cat, deer) help with classifying (dog, frog, horse, ship, truck)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "G9EN9yIPhN2q"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (25000, 32, 32, 3)\n",
      "y_train: (25000,)\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)\n",
    "\n",
    "# Create two datasets: one with classes below 5 and one with 5 and above\n",
    "x_train_lt5 = x_train[y_train < 5]\n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "x_test_lt5 = x_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "\n",
    "# Re-index the labels for classes [5, 6, 7, 8, 9] to [0, 1, 2, 3, 4]\n",
    "x_train_gte5 = x_train[y_train >= 5]\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5\n",
    "x_test_gte5 = x_test[y_test >= 5]\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5\n",
    "\n",
    "# Define the input shape based on the backend\n",
    "img_rows, img_cols = 32, 32\n",
    "if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "print(f\"x_train: {x_train_lt5.shape}\")\n",
    "print(f\"y_train: {y_train_lt5.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-1: Train a CNN model on (airplane, automobile, bird, cat, deer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train CNN models\n",
    "def train_model(\n",
    "    model, x_train, y_train, x_test, y_test, \n",
    "    num_classes, batch_size=64, epochs=10, \n",
    "    learning_rate=1e-3, verbose=1,\n",
    "):\n",
    "\n",
    "    # Convert class vectors to binary class matrices (one-hot encoding)\n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    start_time = time()\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=verbose,\n",
    "        validation_data=(x_test, y_test),\n",
    "    )\n",
    "    training_time = time() - start_time\n",
    "    print(f'Training time (min): {(training_time/60):.2f}')\n",
    "\n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"Test loss: {score[0]:.4f}, Test accuracy: {score[1]:.4f}\")\n",
    "\n",
    "    return history, score[0], score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1605760   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1633733 (6.23 MB)\n",
      "Trainable params: 1633733 (6.23 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the dataset with labels for (airplane, automobile, bird, cat, deer)\n",
    "selected_classes = [0, 1, 2, 3, 4]\n",
    "num_classes = len(selected_classes)\n",
    "\n",
    "# Define a CNN model\n",
    "model_1 = Sequential()\n",
    "model_1.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model_1.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(128, activation='relu'))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Dense(64, activation='relu'))\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 49s 121ms/step - loss: 2.3903 - accuracy: 0.4233 - val_loss: 1.1023 - val_accuracy: 0.5600\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 1.2122 - accuracy: 0.5427 - val_loss: 0.9701 - val_accuracy: 0.6134\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 0.9894 - accuracy: 0.6312 - val_loss: 0.9207 - val_accuracy: 0.6614\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 0.8691 - accuracy: 0.6834 - val_loss: 0.7698 - val_accuracy: 0.7212\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.7729 - accuracy: 0.7226 - val_loss: 0.9856 - val_accuracy: 0.6492\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 49s 126ms/step - loss: 0.7019 - accuracy: 0.7474 - val_loss: 0.7490 - val_accuracy: 0.7250\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 49s 125ms/step - loss: 0.6244 - accuracy: 0.7794 - val_loss: 0.9248 - val_accuracy: 0.6722\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 48s 123ms/step - loss: 0.5629 - accuracy: 0.8024 - val_loss: 0.7960 - val_accuracy: 0.7484\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 49s 124ms/step - loss: 0.4983 - accuracy: 0.8300 - val_loss: 1.1414 - val_accuracy: 0.6778\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 62s 160ms/step - loss: 0.4488 - accuracy: 0.8472 - val_loss: 0.7621 - val_accuracy: 0.7662\n",
      "Training time (min): 8.37\n",
      "Test loss: 0.7621, Test accuracy: 0.7662\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "history, loss, accuracy = train_model(\n",
    "    model_1,\n",
    "    x_train_lt5, y_train_lt5,\n",
    "    x_test_lt5, y_test_lt5,\n",
    "    num_classes=num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters after fine-tuning: 1633733\n"
     ]
    }
   ],
   "source": [
    "# Number of trainable parameters after the model_2\n",
    "trainable_params_model_1 = np.sum([np.prod(var.shape) for var in model_1.trainable_weights])\n",
    "print(f\"Total trainable parameters after fine-tuning: {trainable_params_model_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bIQRUgWhN3O"
   },
   "source": [
    "## PART-2: Transfer Learning\n",
    "Keras allows layers to be \"frozen\" during the training process. That is, some layers would have their weights updated during the training process, while others would not. This is a core part of transfer learning, the ability to train just the last one or several layers.\n",
    "\n",
    "Let us now fine-tune our model in two different ways and compare the overall results:\n",
    "\n",
    "- Freeze all layers except the output layer, and train your model on the classes (dog, frog, horse, ship, truck).\n",
    "- Freeze all layers except the fully connected layer and the output layer, and train your model on the classes (dog, frog, horse, ship, truck). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for fine-tuning\n",
    "def fine_tune_model(\n",
    "        model, trainable_layers, x_train, y_train, x_test, y_test, \n",
    "        num_classes, batch_size=64, epochs=10, learning_rate=1e-3,\n",
    "):\n",
    "    \n",
    "    # Convert class vectors to binary class matrices (one-hot encoding)\n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "    \n",
    "    # Freeze all layers except the specified layers\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Unfreeze the specified layers\n",
    "    for i in trainable_layers:\n",
    "        model.layers[i].trainable = True\n",
    "\n",
    "    # Compile the pre-trained model: model_1\n",
    "    optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    start_time = time()\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=(x_test, y_test),\n",
    "    )\n",
    "\n",
    "    training_time = time() - start_time\n",
    "    print(f'Training time (min): {(training_time/60):.2f}')\n",
    "\n",
    "    # Evaluate the model\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"Test loss: {score[0]:.4f}, Test accuracy: {score[1]:.4f}\")\n",
    "\n",
    "    return history, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze all layers except the output layer (model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy weights from the pre-trained model: model_1\n",
    "model_2 = tf.keras.models.clone_model(model_1)\n",
    "model_2.set_weights(model_1.get_weights())\n",
    "\n",
    "# Freeze all layers except the output layer\n",
    "trainable_layers_model_2 = [len(model_2.layers) - 1]  # Only output layer is trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 28s 68ms/step - loss: 1.4252 - accuracy: 0.5052 - val_loss: 1.0162 - val_accuracy: 0.5942\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 28s 71ms/step - loss: 1.0823 - accuracy: 0.5606 - val_loss: 1.0211 - val_accuracy: 0.5886\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 25s 63ms/step - loss: 1.0805 - accuracy: 0.5679 - val_loss: 1.0128 - val_accuracy: 0.6048\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 25s 63ms/step - loss: 1.0699 - accuracy: 0.5720 - val_loss: 0.9965 - val_accuracy: 0.6124\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 24s 60ms/step - loss: 1.0724 - accuracy: 0.5697 - val_loss: 0.9931 - val_accuracy: 0.6164\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 25s 65ms/step - loss: 1.0634 - accuracy: 0.5759 - val_loss: 0.9887 - val_accuracy: 0.6184\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 25s 64ms/step - loss: 1.0680 - accuracy: 0.5754 - val_loss: 0.9990 - val_accuracy: 0.6100\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 25s 64ms/step - loss: 1.0664 - accuracy: 0.5758 - val_loss: 0.9928 - val_accuracy: 0.6132\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 25s 63ms/step - loss: 1.0673 - accuracy: 0.5770 - val_loss: 0.9945 - val_accuracy: 0.6090\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 25s 64ms/step - loss: 1.0684 - accuracy: 0.5703 - val_loss: 1.0001 - val_accuracy: 0.6060\n",
      "Training time (min): 4.23\n",
      "Test loss: 1.0001, Test accuracy: 0.6060\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune model_2 on the dataset with labels for (dog, frog, horse, ship, truck)\n",
    "selected_classes = [5, 6, 7, 8, 9]\n",
    "num_classes = len(selected_classes)\n",
    "\n",
    "history_exp1, score_exp1 = fine_tune_model(\n",
    "    model_2,\n",
    "    trainable_layers=trainable_layers_model_2,\n",
    "    x_train=x_train_gte5,\n",
    "    y_train=y_train_gte5,\n",
    "    x_test=x_test_gte5,\n",
    "    y_test=y_test_gte5,\n",
    "    num_classes=num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1605760   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1633733 (6.23 MB)\n",
      "Trainable params: 325 (1.27 KB)\n",
      "Non-trainable params: 1633408 (6.23 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the model summary after fine-tuning\n",
    "print(\"After fine-tuning:\")\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters after fine-tuning: 325\n"
     ]
    }
   ],
   "source": [
    "# Number of trainable parameters after the model_2\n",
    "trainable_params_model_2 = np.sum([np.prod(var.shape) for var in model_2.trainable_weights])\n",
    "print(f\"Total trainable parameters after fine-tuning: {trainable_params_model_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze all layers except the fully connected layers and the output layer (model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Copy weights from the pre-trained model: model_1\n",
    "model_3 = tf.keras.models.clone_model(model_1)\n",
    "model_3.set_weights(model_1.get_weights())  \n",
    "\n",
    "# Freeze all layers except the fully connected and output layers\n",
    "trainable_layers_model_3 = [-3, -1]  # Last fully connected layer and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/391 [==============================] - 27s 67ms/step - loss: 1.2184 - accuracy: 0.5502 - val_loss: 0.9170 - val_accuracy: 0.6430\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 25s 65ms/step - loss: 0.9674 - accuracy: 0.6234 - val_loss: 0.8774 - val_accuracy: 0.6702\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 25s 63ms/step - loss: 0.9391 - accuracy: 0.6345 - val_loss: 0.8627 - val_accuracy: 0.6736\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 25s 63ms/step - loss: 0.9182 - accuracy: 0.6450 - val_loss: 0.8410 - val_accuracy: 0.6846\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.9077 - accuracy: 0.6454 - val_loss: 0.8705 - val_accuracy: 0.6634\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 0.9114 - accuracy: 0.6495 - val_loss: 0.8520 - val_accuracy: 0.6738\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 30s 77ms/step - loss: 0.8956 - accuracy: 0.6547 - val_loss: 0.8385 - val_accuracy: 0.6860\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 24s 62ms/step - loss: 0.8957 - accuracy: 0.6585 - val_loss: 0.8449 - val_accuracy: 0.6818\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 25s 63ms/step - loss: 0.8896 - accuracy: 0.6568 - val_loss: 0.8361 - val_accuracy: 0.6792\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 25s 64ms/step - loss: 0.8904 - accuracy: 0.6600 - val_loss: 0.8294 - val_accuracy: 0.6904\n",
      "Training time (min): 4.32\n",
      "Test loss: 0.8294, Test accuracy: 0.6904\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune model_3 on the dataset with labels for (dog, frog, horse, ship, truck)\n",
    "selected_classes = [5, 6, 7, 8, 9]\n",
    "num_classes = len(selected_classes)\n",
    "\n",
    "history_exp2, score_exp2 = fine_tune_model(\n",
    "    model_3,\n",
    "    trainable_layers=trainable_layers_model_3,\n",
    "    x_train=x_train_gte5,\n",
    "    y_train=y_train_gte5,\n",
    "    x_test=x_test_gte5,\n",
    "    y_test=y_test_gte5,\n",
    "    num_classes=num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1605760   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1633733 (6.23 MB)\n",
      "Trainable params: 8581 (33.52 KB)\n",
      "Non-trainable params: 1625152 (6.20 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Check the model summary after fine-tuning\n",
    "print(\"After fine-tuning:\")\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters after fine-tuning: 8581\n"
     ]
    }
   ],
   "source": [
    "# Number of trainable parameters after fine-tuning the model_3\n",
    "trainable_params_model_3 = np.sum([np.prod(var.shape) for var in model_3.trainable_weights])\n",
    "print(f\"Total trainable parameters after fine-tuning: {trainable_params_model_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the results of the baseline and fine-tuned models: model_1, model_2, model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Number of Trainable Parameters</th>\n",
       "      <th>Training Time (min)</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>1633733</td>\n",
       "      <td>8.37</td>\n",
       "      <td>0.84720</td>\n",
       "      <td>0.7662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>325</td>\n",
       "      <td>4.23</td>\n",
       "      <td>0.57032</td>\n",
       "      <td>0.6060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>8581</td>\n",
       "      <td>4.32</td>\n",
       "      <td>0.66004</td>\n",
       "      <td>0.6904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name  Number of Trainable Parameters  Training Time (min)  \\\n",
       "0    model_1                         1633733                 8.37   \n",
       "1    model_2                             325                 4.23   \n",
       "2    model_3                            8581                 4.32   \n",
       "\n",
       "   Train Accuracy  Test Accuracy  \n",
       "0         0.84720         0.7662  \n",
       "1         0.57032         0.6060  \n",
       "2         0.66004         0.6904  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store train and test results into a summary df\n",
    "summary = pd.DataFrame({\n",
    "    \"Model Name\": [\n",
    "        \"model_1\",\n",
    "        \"model_2\",\n",
    "        \"model_3\"\n",
    "    ],\n",
    "    \"Number of Trainable Parameters\": [\n",
    "        trainable_params_model_1,\n",
    "        trainable_params_model_2, \n",
    "        trainable_params_model_3  \n",
    "    ],\n",
    "    \"Training Time (min)\": [\n",
    "        8.37,\n",
    "        4.23,\n",
    "        4.32,\n",
    "    ],\n",
    "    \"Train Accuracy\": [\n",
    "        history.history['accuracy'][-1],     \n",
    "        history_exp1.history['accuracy'][-1],\n",
    "        history_exp2.history['accuracy'][-1] \n",
    "    ],\n",
    "    \"Test Accuracy\": [\n",
    "        accuracy,     \n",
    "        score_exp1[1],\n",
    "        score_exp2[1] \n",
    "    ],\n",
    "})\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "\n",
    "1. How many trainable parameters are there in each case?\n",
    "    - model_1 (baseline): 1,633,733\n",
    "    - model_2 (fine_tuned): 325\n",
    "    - model_3 (fine-tuned): 8581\n",
    "\n",
    "2. Which fine-tuning performs better in terms of classification accuracy and why?\n",
    "\\\n",
    "model_3 exhibited a greater test accuracy of 69% than model_2 with 60.6%. Both models utilize the pre-trained weights from the baseline model, model_1. However, model_3 is exposed to more extensive training since it has more trainable parameters (weights). This helped model_3 learn better from the training data.\n",
    "\n",
    "\n",
    "3. Why is fine-tuning much faster than the initial training of the network?\n",
    "\\\n",
    "The fine-tuned models have fewer trainable parameters (weights) than the baseline model. The classification models aim to update these weights during training to learn patterns from the training data. Thus, the training time for the less-weight models will be less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
